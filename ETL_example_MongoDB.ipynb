{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scubasloth/MLF_1/blob/main/ETL_example_MongoDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU25JOjUgOvF"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5heotUp4gQO7"
      },
      "source": [
        "This is a 'notebook' in Google Colaboratory. It contains a mixture of programming code (in Python), interspersed with comments and descriptions, to explain what's going on.\n",
        "\n",
        "It's a 'live' notebook. That is, you can execute the code contained in the notebook by clicking the play button (triangle inside a circle) next to any of the code cells. You can also edit and change the code before you run it, or you can run it, change it, then run it again to see the changes. It's a good way to experiment with code.\n",
        "\n",
        "You don't really need to know Python coding to use this notebook. In the simplest case you can just run the supplied code and it should work. But if you do know Python, or you want to experiment, you are welcome to.\n",
        "\n",
        "\n",
        "To save your own copy of this notebook, you'll need to save it into Google Drive (or GitHub).\n",
        "\n",
        "This example works through a very simple case of **ETL** - Extract, Transform, Load."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo1CbhAZfSwG"
      },
      "source": [
        "# Extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oEa7O-zgVP7"
      },
      "source": [
        "The first thing we are going to do is to extract some data from your MongoDB Atlas cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmMhBUdFg1Y7"
      },
      "source": [
        "### Import various Python libraries we will need\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjF2km0ufKZ_",
        "outputId": "630f177c-0b99-4d6b-ef33-b707a9e54b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Although PyMongo is already included in Colab, you need the `srv` extra to connect to Atlas:\n",
        "!pip install --upgrade pymongo[srv]\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from bson import ObjectId\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (4.3.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo[srv]) (2.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3uzZCUYlRm_"
      },
      "source": [
        "### Connect to MongoDB Atlas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7eH7q2X0iHe"
      },
      "source": [
        "**In the line below, you can replace the value of MONGODB_URL (the bit inside the quotes) with the one that links to your own MongoDB Atlas database!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge4YiArjlUMe"
      },
      "source": [
        "MONGODB_URL = \"mongodb+srv://pacman:Icesandwichcase@cluster0.zylzy1x.mongodb.net/test\"\n",
        "\n",
        "client = MongoClient(MONGODB_URL)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_NYKBr8lcPM",
        "outputId": "6836fffe-7339-4e0c-affe-9a71ecc2647d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# List database names\n",
        "client.list_database_names()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_airbnb',\n",
              " 'sample_analytics',\n",
              " 'sample_geospatial',\n",
              " 'sample_guides',\n",
              " 'sample_mflix',\n",
              " 'sample_restaurants',\n",
              " 'sample_supplies',\n",
              " 'sample_training',\n",
              " 'sample_weatherdata',\n",
              " 'admin',\n",
              " 'local']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct9mK9o0lgAG"
      },
      "source": [
        "# Choose a database, and list the collections in that database\n",
        "db = client.get_database(\"sample_restaurants\")\n",
        "db.list_collection_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpAlRB9uljK9"
      },
      "source": [
        "# Choose a collection\n",
        "restaurants = db.get_collection(\"restaurants\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXkodqDGl8A8"
      },
      "source": [
        "### Run a query and store results in a Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1iviXDHlpG9"
      },
      "source": [
        "# Run a query (\"find\" operation)\n",
        "#results = restaurants.find({\"borough\":\"Brooklyn\"})\n",
        "results = restaurants.find()\n",
        "\n",
        "# We need to do some type manipulation - convert our Cursor of results into a list, then convert the list into a Pandas DataFrame\n",
        "results_list = list(results)\n",
        "df = pd.DataFrame(results_list)\n",
        "\n",
        "# Print out the first few rows of the DataFrame\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix40eDm2l2H0"
      },
      "source": [
        "# Show total number of documents in the collection\n",
        "print (len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W7ihPFmmX6-"
      },
      "source": [
        "### Explore the data a little bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--R85oEGmbCv"
      },
      "source": [
        "# Count the number of documents in each borough\n",
        "df['borough'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nerud0oCml5S"
      },
      "source": [
        "# Count the number of documents for each cuisine\n",
        "df['cuisine'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VccFtwKpnVJr"
      },
      "source": [
        "# Just for fun we can even create a little bar chart and visualise the number of restaurants in each borough\n",
        "df['borough'].value_counts().plot(kind='bar');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE3LZyymnpbv"
      },
      "source": [
        "Hmm, it looks like some of the borough's have 'Missing' as their value. We'll come back to that data quality issue in a minute.\n",
        "\n",
        "You might notice that even up above when we showed the list of borough's, there was 'Missing' mentioned. But it seems to stand out more when you show it in a bar chart, don't you think?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-AF2Gxxn7VL"
      },
      "source": [
        "# Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc6lWoLzn9Ay"
      },
      "source": [
        "Now that we've extracted the data and had a bit of a look at it, we can apply some transformations. Note that we're processing the data as a batch here, not streaming transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNcFg3CioUhg"
      },
      "source": [
        "### Deal with missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY-xgDuTpezD"
      },
      "source": [
        "We noticed above that some documents have 'Missing' as the borough name. When cleaning/transforming the data, we need to decide what to do with them. We could:\n",
        "* remove those rows entirely\n",
        "* change 'Missing' to some other value\n",
        "\n",
        "If it was numeric data we could consider taking the mean or median value, but as it's a text field that's not applicable.\n",
        "\n",
        "Let's say that we want our data warehouse to only have clean data, so we'll just remove those rows entirely from the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA1u1QixoST_"
      },
      "source": [
        "# We'll create a new DataFrame called transformed that consists of all documents from the original set where the borough is NOT 'Missing'\n",
        "transformed = df[df.borough != \"Missing\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N235qrxmpNnh"
      },
      "source": [
        "# To verify this, let's count the number of documents for each borough again. There now shouldn't be any with 'Missing'\n",
        "transformed['borough'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xJxQLsRpqK9"
      },
      "source": [
        "### Rewrite values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsSmZ2qXpt5G"
      },
      "source": [
        "Maybe the data we are importing doesn't match the data model used in our data warehouse. We might need to transform or change some of the values in the input data so that it matches what we want it to be.\n",
        "\n",
        "Let's look at all the possible (unique) cuisine types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOTp_L1zs525"
      },
      "source": [
        "print (df['cuisine'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iZPDBnotrp-"
      },
      "source": [
        "There's some data quality issues in there.  Cafes seem to have two different entries:\n",
        "* Café/Coffee/<wbr>Tea\n",
        "* CafÃ©/Coffee/<wbr>Tea\n",
        "\n",
        "The fact that there's two different terms representing the same thing is a problem. It's also a bit cumbersome if you wanted to query the data.\n",
        "\n",
        "Maybe in our data warehouse we want to change both of these to just simply 'Cafe'. So we want to change all cuisine types from one value to another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMoZgJfsp6Y2"
      },
      "source": [
        "# Change all occurrences of 'Café/Coffee/Tea' to simply 'Cafe'\n",
        "transformed.loc[(transformed.cuisine == 'Café/Coffee/Tea'),'cuisine']='Cafe'\n",
        "transformed.loc[(transformed.cuisine == 'CafÃ©/Coffee/Tea'),'cuisine']='Cafe'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jFK9PkjqW1o"
      },
      "source": [
        "# To verify this, let's count the number of documents for each cuisine type again. Now it should show 'Cafe' instead of what was there before.\n",
        "transformed['cuisine'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-EyMke8yu7c"
      },
      "source": [
        "### Select columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgwqJ8LByw1c"
      },
      "source": [
        "Maybe we don't want to load all columns from the original data into our data warehouse.\n",
        "\n",
        "The original data contains a column called 'grades'. Let's delete this column entirely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g_9wVbhy818"
      },
      "source": [
        "# Delete the 'grades' column\n",
        "del transformed['grades']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0euU9Fk6zEOc"
      },
      "source": [
        "# Print out the first few rows again, just so we can see that column is gone now\n",
        "transformed.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRf353sHuuG9"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Qy9J8VuwF1"
      },
      "source": [
        "Now that we've extracted our data and transformed it, it's time to load it.\n",
        "\n",
        "In this example, for simplicity we'll just load it back into the same MongoDB Atlas database that we extracted it from, but put it into a new collection.\n",
        "\n",
        "Normally of course you would load it into a different database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdTkhPOfvEGU"
      },
      "source": [
        "# Create a new collection in the database. Note that with MongoDB the collection doesn't actually exist until we put some data into it (next step)\n",
        "# Our new collection will be called \"new_restaurants\"\n",
        "newcollection = db[\"new_restaurants\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ZSvGiIwruS"
      },
      "source": [
        "# Just in case the new collection has data in it (because we re-ran this notebook several times), let's delete all documents in it.\n",
        "delete_result = newcollection.delete_many({})\n",
        "print(delete_result.deleted_count, \" documents deleted.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_KgWcKlvU09"
      },
      "source": [
        "# Insert the records (documents) from our 'transformed' Pandas DataFrame into the new collection\n",
        "# Note that if you try to run this twice without first deleting all the documents, you will get an error about inserting duplicates. That's OK, just delete them (previous code block) first\n",
        "insert_result = newcollection.insert_many(transformed.to_dict('records'))\n",
        "if insert_result.acknowledged:\n",
        "  print (\"Insert successful\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWjKUdDEvf_0"
      },
      "source": [
        "Now log in to your MongoDB Atlas cluster, and look at your list of databases and collections.\n",
        "\n",
        "In the 'restaurants' database, there should now be another collection called 'new_restaurants'.\n",
        "\n",
        "How many documents are in the new collection compared with the original one?\n",
        "\n",
        "Verify that there is no 'grades' attribute in the new collection either."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_sfJ9-lzh9R"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQAdypW6zjkp"
      },
      "source": [
        "We've just seen a very simple ETL example where we extracted some data from a database, applied some transformations, then loaded it back into another database.\n",
        "\n",
        "The purpose is just to illustrate at a very basic level how a data engineer might create code that implements batch ETL processing on data. If you don't know Python code and didn't really understand the code, that's fine - it's more about understanding the steps, and being able to try them out.\n",
        "\n",
        "Even if you don't know Python though, one thing you might have noticed along the way is that most steps only required 1 or 2 lines of code. We could transform an entire data set with a single instruction. That's the power of ETL - being able to automate data pipelines with simple instructions."
      ]
    }
  ]
}